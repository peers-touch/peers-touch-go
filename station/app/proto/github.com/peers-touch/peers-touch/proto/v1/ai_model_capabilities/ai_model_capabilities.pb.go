// PEERS_GENERATION_CONFIG:
//   targets: [backend, desktop, mobile]
//   model_only: true

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v5.29.3
// source: ai_model_capabilities.proto

package ai_model_capabilities

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// ModelProvider 定义了AI模型的提供商
type ModelProvider int32

const (
	ModelProvider_MODEL_PROVIDER_UNSPECIFIED ModelProvider = 0
	ModelProvider_OPENAI                     ModelProvider = 1
	ModelProvider_GOOGLE                     ModelProvider = 2
	ModelProvider_ANTHROPIC                  ModelProvider = 3
	ModelProvider_MOONSHOT                   ModelProvider = 4
	ModelProvider_OLLAMA                     ModelProvider = 5 // 本地模型
	ModelProvider_CUSTOM                     ModelProvider = 6 // 自定义或社区模型
)

// Enum value maps for ModelProvider.
var (
	ModelProvider_name = map[int32]string{
		0: "MODEL_PROVIDER_UNSPECIFIED",
		1: "OPENAI",
		2: "GOOGLE",
		3: "ANTHROPIC",
		4: "MOONSHOT",
		5: "OLLAMA",
		6: "CUSTOM",
	}
	ModelProvider_value = map[string]int32{
		"MODEL_PROVIDER_UNSPECIFIED": 0,
		"OPENAI":                     1,
		"GOOGLE":                     2,
		"ANTHROPIC":                  3,
		"MOONSHOT":                   4,
		"OLLAMA":                     5,
		"CUSTOM":                     6,
	}
)

func (x ModelProvider) Enum() *ModelProvider {
	p := new(ModelProvider)
	*p = x
	return p
}

func (x ModelProvider) String() string {
	return protoimpl.X.EnumStringOf(x.Descriptor(), protoreflect.EnumNumber(x))
}

func (ModelProvider) Descriptor() protoreflect.EnumDescriptor {
	return file_ai_model_capabilities_proto_enumTypes[0].Descriptor()
}

func (ModelProvider) Type() protoreflect.EnumType {
	return &file_ai_model_capabilities_proto_enumTypes[0]
}

func (x ModelProvider) Number() protoreflect.EnumNumber {
	return protoreflect.EnumNumber(x)
}

// Deprecated: Use ModelProvider.Descriptor instead.
func (ModelProvider) EnumDescriptor() ([]byte, []int) {
	return file_ai_model_capabilities_proto_rawDescGZIP(), []int{0}
}

// ModelCapability 定义了单个AI模型所支持的各种能力
type ModelCapability struct {
	state       protoimpl.MessageState `protogen:"open.v1"`
	Id          string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`                                                // 模型唯一ID, e.g., "gpt-4-turbo"
	DisplayName string                 `protobuf:"bytes,2,opt,name=display_name,json=displayName,proto3" json:"display_name,omitempty"`           // 用于UI展示的名称, e.g., "GPT-4 Turbo"
	Provider    ModelProvider          `protobuf:"varint,3,opt,name=provider,proto3,enum=peers_touch.v1.ModelProvider" json:"provider,omitempty"` // 模型提供商
	// --- 多模态能力标识 ---
	VisionSupported      bool `protobuf:"varint,4,opt,name=vision_supported,json=visionSupported,proto3" json:"vision_supported,omitempty"`                  // 是否支持图像输入 (识图)
	FileUploadSupported  bool `protobuf:"varint,5,opt,name=file_upload_supported,json=fileUploadSupported,proto3" json:"file_upload_supported,omitempty"`    // 是否支持文件上传用于知识库/RAG
	TtsSupported         bool `protobuf:"varint,6,opt,name=tts_supported,json=ttsSupported,proto3" json:"tts_supported,omitempty"`                           // 是否支持文本转语音 (Text-to-Speech)
	SttSupported         bool `protobuf:"varint,7,opt,name=stt_supported,json=sttSupported,proto3" json:"stt_supported,omitempty"`                           // 是否支持语音转文本 (Speech-to-Text)
	ToolCallingSupported bool `protobuf:"varint,8,opt,name=tool_calling_supported,json=toolCallingSupported,proto3" json:"tool_calling_supported,omitempty"` // 是否支持工具调用 (Function Calling)
	WebSearchSupported   bool `protobuf:"varint,9,opt,name=web_search_supported,json=webSearchSupported,proto3" json:"web_search_supported,omitempty"`       // 是否支持联网搜索
	// --- 能力相关参数 ---
	MaxVisionInput   int32 `protobuf:"varint,10,opt,name=max_vision_input,json=maxVisionInput,proto3" json:"max_vision_input,omitempty"`       // 支持的最大图片输入数量
	MaxContextWindow int64 `protobuf:"varint,11,opt,name=max_context_window,json=maxContextWindow,proto3" json:"max_context_window,omitempty"` // 最大上下文窗口大小 (tokens)
	unknownFields    protoimpl.UnknownFields
	sizeCache        protoimpl.SizeCache
}

func (x *ModelCapability) Reset() {
	*x = ModelCapability{}
	mi := &file_ai_model_capabilities_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelCapability) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelCapability) ProtoMessage() {}

func (x *ModelCapability) ProtoReflect() protoreflect.Message {
	mi := &file_ai_model_capabilities_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelCapability.ProtoReflect.Descriptor instead.
func (*ModelCapability) Descriptor() ([]byte, []int) {
	return file_ai_model_capabilities_proto_rawDescGZIP(), []int{0}
}

func (x *ModelCapability) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ModelCapability) GetDisplayName() string {
	if x != nil {
		return x.DisplayName
	}
	return ""
}

func (x *ModelCapability) GetProvider() ModelProvider {
	if x != nil {
		return x.Provider
	}
	return ModelProvider_MODEL_PROVIDER_UNSPECIFIED
}

func (x *ModelCapability) GetVisionSupported() bool {
	if x != nil {
		return x.VisionSupported
	}
	return false
}

func (x *ModelCapability) GetFileUploadSupported() bool {
	if x != nil {
		return x.FileUploadSupported
	}
	return false
}

func (x *ModelCapability) GetTtsSupported() bool {
	if x != nil {
		return x.TtsSupported
	}
	return false
}

func (x *ModelCapability) GetSttSupported() bool {
	if x != nil {
		return x.SttSupported
	}
	return false
}

func (x *ModelCapability) GetToolCallingSupported() bool {
	if x != nil {
		return x.ToolCallingSupported
	}
	return false
}

func (x *ModelCapability) GetWebSearchSupported() bool {
	if x != nil {
		return x.WebSearchSupported
	}
	return false
}

func (x *ModelCapability) GetMaxVisionInput() int32 {
	if x != nil {
		return x.MaxVisionInput
	}
	return 0
}

func (x *ModelCapability) GetMaxContextWindow() int64 {
	if x != nil {
		return x.MaxContextWindow
	}
	return 0
}

// ModelProviderCapabilitiesResponse 用于后端返回给前端的所有可用模型及其能力
type ModelProviderCapabilitiesResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Capabilities  []*ModelCapability     `protobuf:"bytes,1,rep,name=capabilities,proto3" json:"capabilities,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelProviderCapabilitiesResponse) Reset() {
	*x = ModelProviderCapabilitiesResponse{}
	mi := &file_ai_model_capabilities_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelProviderCapabilitiesResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelProviderCapabilitiesResponse) ProtoMessage() {}

func (x *ModelProviderCapabilitiesResponse) ProtoReflect() protoreflect.Message {
	mi := &file_ai_model_capabilities_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelProviderCapabilitiesResponse.ProtoReflect.Descriptor instead.
func (*ModelProviderCapabilitiesResponse) Descriptor() ([]byte, []int) {
	return file_ai_model_capabilities_proto_rawDescGZIP(), []int{1}
}

func (x *ModelProviderCapabilitiesResponse) GetCapabilities() []*ModelCapability {
	if x != nil {
		return x.Capabilities
	}
	return nil
}

var File_ai_model_capabilities_proto protoreflect.FileDescriptor

const file_ai_model_capabilities_proto_rawDesc = "" +
	"\n" +
	"\x1bai_model_capabilities.proto\x12\x0epeers_touch.v1\"\xe8\x03\n" +
	"\x0fModelCapability\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12!\n" +
	"\fdisplay_name\x18\x02 \x01(\tR\vdisplayName\x129\n" +
	"\bprovider\x18\x03 \x01(\x0e2\x1d.peers_touch.v1.ModelProviderR\bprovider\x12)\n" +
	"\x10vision_supported\x18\x04 \x01(\bR\x0fvisionSupported\x122\n" +
	"\x15file_upload_supported\x18\x05 \x01(\bR\x13fileUploadSupported\x12#\n" +
	"\rtts_supported\x18\x06 \x01(\bR\fttsSupported\x12#\n" +
	"\rstt_supported\x18\a \x01(\bR\fsttSupported\x124\n" +
	"\x16tool_calling_supported\x18\b \x01(\bR\x14toolCallingSupported\x120\n" +
	"\x14web_search_supported\x18\t \x01(\bR\x12webSearchSupported\x12(\n" +
	"\x10max_vision_input\x18\n" +
	" \x01(\x05R\x0emaxVisionInput\x12,\n" +
	"\x12max_context_window\x18\v \x01(\x03R\x10maxContextWindow\"h\n" +
	"!ModelProviderCapabilitiesResponse\x12C\n" +
	"\fcapabilities\x18\x01 \x03(\v2\x1f.peers_touch.v1.ModelCapabilityR\fcapabilities*|\n" +
	"\rModelProvider\x12\x1e\n" +
	"\x1aMODEL_PROVIDER_UNSPECIFIED\x10\x00\x12\n" +
	"\n" +
	"\x06OPENAI\x10\x01\x12\n" +
	"\n" +
	"\x06GOOGLE\x10\x02\x12\r\n" +
	"\tANTHROPIC\x10\x03\x12\f\n" +
	"\bMOONSHOT\x10\x04\x12\n" +
	"\n" +
	"\x06OLLAMA\x10\x05\x12\n" +
	"\n" +
	"\x06CUSTOM\x10\x06BCZAgithub.com/peers-touch/peers-touch/proto/v1/ai_model_capabilitiesb\x06proto3"

var (
	file_ai_model_capabilities_proto_rawDescOnce sync.Once
	file_ai_model_capabilities_proto_rawDescData []byte
)

func file_ai_model_capabilities_proto_rawDescGZIP() []byte {
	file_ai_model_capabilities_proto_rawDescOnce.Do(func() {
		file_ai_model_capabilities_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_ai_model_capabilities_proto_rawDesc), len(file_ai_model_capabilities_proto_rawDesc)))
	})
	return file_ai_model_capabilities_proto_rawDescData
}

var file_ai_model_capabilities_proto_enumTypes = make([]protoimpl.EnumInfo, 1)
var file_ai_model_capabilities_proto_msgTypes = make([]protoimpl.MessageInfo, 2)
var file_ai_model_capabilities_proto_goTypes = []any{
	(ModelProvider)(0),                        // 0: peers_touch.v1.ModelProvider
	(*ModelCapability)(nil),                   // 1: peers_touch.v1.ModelCapability
	(*ModelProviderCapabilitiesResponse)(nil), // 2: peers_touch.v1.ModelProviderCapabilitiesResponse
}
var file_ai_model_capabilities_proto_depIdxs = []int32{
	0, // 0: peers_touch.v1.ModelCapability.provider:type_name -> peers_touch.v1.ModelProvider
	1, // 1: peers_touch.v1.ModelProviderCapabilitiesResponse.capabilities:type_name -> peers_touch.v1.ModelCapability
	2, // [2:2] is the sub-list for method output_type
	2, // [2:2] is the sub-list for method input_type
	2, // [2:2] is the sub-list for extension type_name
	2, // [2:2] is the sub-list for extension extendee
	0, // [0:2] is the sub-list for field type_name
}

func init() { file_ai_model_capabilities_proto_init() }
func file_ai_model_capabilities_proto_init() {
	if File_ai_model_capabilities_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_ai_model_capabilities_proto_rawDesc), len(file_ai_model_capabilities_proto_rawDesc)),
			NumEnums:      1,
			NumMessages:   2,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_ai_model_capabilities_proto_goTypes,
		DependencyIndexes: file_ai_model_capabilities_proto_depIdxs,
		EnumInfos:         file_ai_model_capabilities_proto_enumTypes,
		MessageInfos:      file_ai_model_capabilities_proto_msgTypes,
	}.Build()
	File_ai_model_capabilities_proto = out.File
	file_ai_model_capabilities_proto_goTypes = nil
	file_ai_model_capabilities_proto_depIdxs = nil
}
